{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DecisionTreeTutorial",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "165CSmT99w4_Sv1UENIyvIkH7ZEw2Xeh8",
          "timestamp": 1527780043079
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "-UimMCmGe19F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Decision Trees\n"
      ]
    },
    {
      "metadata": {
        "id": "79hUhSH_ysa7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Supervised learning algorithm (so labeled data) <br>\n",
        "Intuitive, general concept easy to grasp which is a benefit for operational use <br>"
      ]
    },
    {
      "metadata": {
        "id": "M4b_cIfyzzWE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i0.wp.com/dataaspirant.com/wp-content/uploads/2017/01/B03905_05_01-compressor.png?resize=768%2C424&ssl=1\">"
      ]
    },
    {
      "metadata": {
        "id": "llB5Ys6g0gLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(Upside down) tree structure is a common way to visualize computer science data structures <br>\n",
        "The top node is called the root node <br>\n",
        "The nodes with out any outgoing branches are the leaf nodes and these are the labels, in this case \"accept offer\", \"decline offer\" <br>"
      ]
    },
    {
      "metadata": {
        "id": "JDWUHcQo0gNL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Any given input begins with the question of the root node and moves along the branches according to the decisions and what leaf node the questions lead to determines the classification of the input <br>"
      ]
    },
    {
      "metadata": {
        "id": "fAIY0MPN2s-f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The questions must be yes or no answers, no continuous answers <br>\n",
        "Continuous answers must be discretized <br>\n",
        "For instance, do not ask for the age of a person, instead ask if the person is over 25"
      ]
    },
    {
      "metadata": {
        "id": "BhsxxB_R2tAN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Choosing which features/questions are at the root and near the top of the tree is important <br>\n",
        "You want more indicative features/questions to be asked earlier "
      ]
    },
    {
      "metadata": {
        "id": "8x8DfbTDJY1f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Common parameters to tune:\n",
        "    Feature Selection\n",
        "    Maximum Depth\n",
        "    Minimum Sample Leafs"
      ]
    },
    {
      "metadata": {
        "id": "LLhN59Dn2tCX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Feature Selection Methods\n",
        "What questions do you ask? What decisions best divide the data?"
      ]
    },
    {
      "metadata": {
        "id": "Or2d94f05bLa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2 common methods: Gini and Entropy <br>\n",
        "Can treat as a parameter and try both methods and see which performs better!"
      ]
    },
    {
      "metadata": {
        "id": "nuBvDBYV3aAv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Gini"
      ]
    },
    {
      "metadata": {
        "id": "BXgWk-Wf5_gX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"http://www.learnbymarketing.com/wp-content/uploads/2016/02/gini-index-formula.png\">"
      ]
    },
    {
      "metadata": {
        "id": "-53QWSUp62n5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "P<sub>i</sub> is probability of class i        &emsp;       i.e) There are 10 jobs with free coffee and 10 jobs without free coffee the probability of each class is .5<br>\n",
        "c is number of classes"
      ]
    },
    {
      "metadata": {
        "id": "Ov7c1FBN3aCc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Entropy"
      ]
    },
    {
      "metadata": {
        "id": "-Gxw6Mkv3aEt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"http://www.learnbymarketing.com/wp-content/uploads/2016/02/entropy-formula.png\">"
      ]
    },
    {
      "metadata": {
        "id": "-jkI7Jxe4_Yr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You want to minimize entropy/gini values<br>\n",
        "Gini  favors larger partitions and Entropy favors smaller partitions that have small counts <br>\n",
        "In practice, try both and see what gives better results for given problem "
      ]
    },
    {
      "metadata": {
        "id": "oVPSx0ObEwyw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you want a more indepth look at the entropy/gini calculations the link below steps through some examples <br>\n",
        "http://www.learnbymarketing.com/481/decision-tree-flavors-gini-info-gain/"
      ]
    },
    {
      "metadata": {
        "id": "m1rYtElYGr2d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Maximum Depth"
      ]
    },
    {
      "metadata": {
        "id": "lk2odiBkHoVb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Depth in a computer science tree is the number of edges from the root node"
      ]
    },
    {
      "metadata": {
        "id": "bJwkeB-AH-Fw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.stack.imgur.com/RHEqu.png\">  "
      ]
    },
    {
      "metadata": {
        "id": "_FhuillkIP4U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In many cases you want to set a limit on the maximum depth to prevent from overfitting <br>\n",
        "Otherwise the questions may become very specific to the training data and not generalize well to data not seen"
      ]
    },
    {
      "metadata": {
        "id": "xw5HZSPdG8Ca",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Minimum Sample Leafs"
      ]
    },
    {
      "metadata": {
        "id": "h1zysauJKKfN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Minimum number of samples required for a leaf node <br>\n",
        "Similar to maximum depth main goal is to prevent from overfitting <br>\n",
        "If a leaf node from the training data contains only one sample, then the decisions that led to this leaf node may be specific to the training data and not generalizable "
      ]
    },
    {
      "metadata": {
        "id": "mAMrGZWVib09",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Random Forests"
      ]
    },
    {
      "metadata": {
        "id": "nWmmufZzig4l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Decision trees have a tendency to overfit. So perhaps several decision trees run in parrallel and then averaged together create a better classificaiton. This ensemble is known as a random forest.  <br> <br>\n",
        "\n",
        "New input is run down all the trees and then combined by some method. The method may be treating each tree's result as a vote (and the most popular label wins), the ensemble method may average across the probabilities of the predictions, etc."
      ]
    },
    {
      "metadata": {
        "id": "tltXjbOLfES-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i0.wp.com/analyticsdefined.com/wp-content/uploads/2018/01/random-forests.png?fit=1965%2C942&ssl=1\">"
      ]
    }
  ]
}