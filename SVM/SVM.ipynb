{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "165CSmT99w4_Sv1UENIyvIkH7ZEw2Xeh8",
          "timestamp": 1527780043079
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "cknVeYO9l871",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Support Vector Machine"
      ]
    },
    {
      "metadata": {
        "id": "q71qY1utlDUm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<ul> Supervised machine learning which is mainly used for classification but can be used for regression  </ul>\n",
        "\n",
        "<ul> Each data item is a vector point in n-dimensional space, where n is the number of features </ul>\n",
        "\n",
        "<ul> Classification is finding the hyper plane that best differentiates the two classes </ul>\n"
      ]
    },
    {
      "metadata": {
        "id": "WOaBNZvtm7vh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below is a simple example with 2 dimension/features"
      ]
    },
    {
      "metadata": {
        "id": "YcznDcVEm74q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2015/10/SVM_1.png\">"
      ]
    },
    {
      "metadata": {
        "id": "3bUqmLmWZe_G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## How do you find the hyper-plane \n",
        "<li>Seperate the Data</li>\n",
        "<li>Maximize the Margin </li>"
      ]
    },
    {
      "metadata": {
        "id": "cT4M-yR5efQ1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Discriminate the training data into appropriate classes"
      ]
    },
    {
      "metadata": {
        "id": "-5gGl1KOd3uF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/BeaverWorksMedlytics/Week1/blob/master/images/svm_1.png?raw=true\">"
      ]
    },
    {
      "metadata": {
        "id": "g82XP_degjEz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####  However, just finding the  separator that best divides the classes is not sufficient as many lines divide the classes in this case <br>\n",
        "#### For instance, The red x below could be in either class depending on which line was chosen <br>\n",
        "\n",
        "<img src=\"https://github.com/BeaverWorksMedlytics/Week1/blob/master/images/svm_2.png?raw=true\">"
      ]
    },
    {
      "metadata": {
        "id": "GZNx_H6Ti2LE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Maximize the Margin\n",
        "\n",
        "#### The line that maximizes the margin is the optimal model\n",
        "\n",
        "<img src=\"https://github.com/BeaverWorksMedlytics/Week1/blob/master/images/svm_3.png?raw=true\">"
      ]
    },
    {
      "metadata": {
        "id": "vfvZCdtTla0p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Support Vectors\n",
        "\n",
        "#### Vectors that are on the margins are called the support vectors <br>\n",
        "#### support vectors are crucial data points for defining the model's fit <br>\n",
        "#### Other vector's do not change the fit, and the position and number of other vectors does not matter as long as they are outside the support vectors <br>\n",
        "##### This helps explain why svm's can have solid results on small datasets, if there are valuable support vectors\n",
        "\n",
        "<img src=\"https://github.com/BeaverWorksMedlytics/Week1/blob/master/images/svm_4.png?raw=true\">"
      ]
    },
    {
      "metadata": {
        "id": "cfkCa4Awn01o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Kernels"
      ]
    },
    {
      "metadata": {
        "id": "ougllEmVzeVN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "SVM's with linear discriminators are efficient and work well enough in many cases. <br>\n",
        "However, in some cases (like the data pictured below) a linear discriminator is not very effective <br>\n",
        "\n",
        "<img src=\"https://github.com/BeaverWorksMedlytics/Week1/blob/master/images/svm_5.png?raw=true\">\n"
      ]
    },
    {
      "metadata": {
        "id": "YOV8iE8B15cr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The solution is to project the data to a higher dimension <br>\n",
        "Below we see the projection computed by a radial basis function  <br>\n",
        "It is easy to see how a plane could be drawn through the data now\n",
        "\n",
        "### Radial Basis Function (RBF)\n",
        "\n",
        "<img src=\"https://github.com/BeaverWorksMedlytics/Week1/blob/master/images/svm_6.png?raw=true\">\n",
        "<br><br>\n",
        "If you want to see the math theory behind RBF, I suggest [this link]( https://stats.stackexchange.com/questions/58585/how-to-understand-effect-of-rbf-svm) . Otherwise, the relevant paramters and their effects on the algorithm are below"
      ]
    },
    {
      "metadata": {
        "id": "ZNSyN_yxx-f2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Gamma (paramater for RBF)\n",
        " <ul>\n",
        "  <li>SVMs are looking for a hyperplane with the largest margin and correctly divides the training data, the Gamma paramter impacts the margin </li>\n",
        "  <li>Low values of gamma mean the reach of training examples is far </li>\n",
        "  <li>High values of gamma means the reach of training examples is close</li>\n",
        "  </ul>\n",
        "\n",
        "<img src=\"https://github.com/BeaverWorksMedlytics/Week1/blob/master/images/svm_7.PNG?raw=true\">\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1rGC8mJhx-tF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### C (paramter)\n",
        " <ul>\n",
        "  <li>SVMs are looking for a hyperplane with the largest margin and correctly divides the training data, the C paramter impacts the divison of data </li>\n",
        "  <li>C with a low value creates a smooth decision boundary </li>\n",
        "  <li>C with a high values encourages a decision boundary that correctly labels all training examples even if the boundary is very specific to the training example </li>\n",
        "  </ul>\n"
      ]
    },
    {
      "metadata": {
        "id": "VSpTJFYIxK9H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pros\n",
        "<ul>\n",
        "  <li>Models are fast and take up small memory as it just depends on the support vectors </li>  \n",
        "  <li>Work well with limited amount of data that has a lot of attributes </li> \n",
        "</ul>\n"
      ]
    },
    {
      "metadata": {
        "id": "FudC6m1uxKt4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cons\n",
        "<ul>\n",
        "  <li>When large amounts of data are involved often doesn't perform as well as neural networks </li>  \n",
        "  <li>Results are very dependent on parameters, easier to tune paramters with large amounts of data</li> \n",
        "</ul>"
      ]
    }
  ]
}