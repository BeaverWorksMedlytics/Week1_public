{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "57SCOcInULbj"
   },
   "source": [
    "# Classifier Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sZdLALtSf_i"
   },
   "source": [
    "## **Topics**\n",
    "*  Motivation for model evaluation\n",
    "*  Model evaluation procedure\n",
    "*  Model evaluation metrics:\n",
    " *  Accuracy\n",
    " *  Confusion matrix\n",
    " *  Precision, Recall, F1\n",
    " *  Receiver Operating Characteristic (ROC) Curves\n",
    " *  Area Under the Curve (AUC)\n",
    "\n",
    "\n",
    "*This tutorial is derived from Data School's Machine Learning with scikit-learn tutorial. *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oBz9FrOZTAv2"
   },
   "source": [
    "## **Why are we already talking about model evaluation?**\n",
    "\n",
    " *   We need a way to choose between different model types, tuning parameters, and features\n",
    " *   Model evaluation enables us to estimate how well a model will generalize to out-of-sample data\n",
    " *   A model evaluation metric (or many!) required to quantify the model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwJVWtTVTWbz"
   },
   "source": [
    "## **Model evaluation procedure:**\n",
    "1. Split the dataset into a TRAINING set and TESTING set.  Put the testing data set aside and do not use it for any part of model training.\n",
    "2. Leave out part of the TRAINING set as a VALIDATION set.\n",
    "3. Train the model on only the TRAINING data set.\n",
    "4. Evaluate model performance on the VALIDATION set.\n",
    "5. Repeat steps 2+ as necessary.\n",
    "6. Only once the model has been finalized, should you evaluate on the left-out TESTING set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QoU7RS38TWmr"
   },
   "source": [
    "### **Classification Data Set**\n",
    "In this notebook we will work with the popular [PIMA Indians diabetes dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database/version/1). The goal is to predict whether or not a given female patient will contract diabetes based on certain diagnostic measurements. This is a ***binary*** classification problem. An outcome value of 0 indicates that the patient does not have diabetes, while an outcome of 1 indicates that the patient does have diabetes. \n",
    "\n",
    "(Note: We will not discuss regression evaluation in this notebook, but feel free to ask!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4655,
     "status": "ok",
     "timestamp": 1531079082455,
     "user": {
      "displayName": "Danelle Shah",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100860318553187717982"
     },
     "user_tz": 240
    },
    "id": "ym-sI1JMfPT3",
    "outputId": "4f701a79-bb4e-4839-8c15-314085e3bd7b"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "!pip install graphviz \n",
    "!apt-get install graphviz\n",
    "\n",
    "import graphviz \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 399,
     "status": "ok",
     "timestamp": 1531079085072,
     "user": {
      "displayName": "Danelle Shah",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100860318553187717982"
     },
     "user_tz": 240
    },
    "id": "bX7xCiaESvv2",
    "outputId": "611378c0-ada1-40d5-d788-d71a66666c3c"
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "data_url = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/diabetes.csv'\n",
    "data = pd.read_csv(data_url)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u5SL40nidJrz"
   },
   "source": [
    "The columns correspond to the following features:\n",
    "*  **Pregnancies:** Number of times pregnant\n",
    "* **Glucose: ** Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "* **BloodPressure: ** Diastolic blood pressure (mm Hg)\n",
    "* **SkinThickness: ** Triceps skin fold thickness (mm)\n",
    "* **Insulin: ** 2-Hour serum insulin (mu U/ml)\n",
    "* **BMI: ** Body mass index (weight in kg/(height in m)^2)\n",
    "* **DiabetesPedigreeFunction: ** Diabetes pedigree function\n",
    "* **Age: ** Age (years)\n",
    "* **Outcome: ** Whether or not the woman has diabetes (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zJPvQo9kdgKb"
   },
   "outputs": [],
   "source": [
    "# define features (X) and labels (y)\n",
    "feature_names = ['Pregnancies','Glucose','BloodPressure','SkinThickness','BMI','Age']\n",
    "X = data.loc[:, feature_names]\n",
    "y = data.Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UeWjHRSd6HhQ"
   },
   "source": [
    "### Split the data set into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2jJdDuQystTL"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# further split X and y into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kYzKhOU36Ms9"
   },
   "source": [
    "### Train a model on the training data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1531079089388,
     "user": {
      "displayName": "Danelle Shah",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100860318553187717982"
     },
     "user_tz": 240
    },
    "id": "8-x6Uhcas3kn",
    "outputId": "c44ec621-61b3-42cb-a27f-836f554d54fa"
   },
   "outputs": [],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# instantiate model\n",
    "model = DecisionTreeClassifier(max_depth=4,random_state=0)\n",
    "\n",
    "# fit model\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 490,
     "status": "ok",
     "timestamp": 1531079091194,
     "user": {
      "displayName": "Danelle Shah",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100860318553187717982"
     },
     "user_tz": 240
    },
    "id": "FEr2Zey7tREn",
    "outputId": "da504174-c5ff-4d2b-de9f-f9c204c2dc1b"
   },
   "outputs": [],
   "source": [
    "# visualize the decision tree\n",
    "dot_data = tree.export_graphviz(model, out_file=None, \n",
    "                         feature_names=feature_names,  \n",
    "                         class_names=['No Diabetes','Diabetes'],  \n",
    "                         filled=True, rounded=True,\n",
    "                         max_depth=4) \n",
    "\n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CumutApe6SdZ"
   },
   "source": [
    "### Evaluate the model on the validation data set\n",
    "\n",
    "For now, we will use the model to predict the binary classes of our validation data.  \n",
    "Later we'll look at the case where our model outputs a probability over class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GtJigb1SuTRF"
   },
   "outputs": [],
   "source": [
    "# make class predictions for the training validation set\n",
    "y_val_predict = model.predict(X_val)\n",
    "y_train_predict = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1531081256900,
     "user": {
      "displayName": "Danelle Shah",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100860318553187717982"
     },
     "user_tz": 240
    },
    "id": "WuOp6VQ4wq9C",
    "outputId": "154bb73c-ffa8-4968-853b-5281581cea46"
   },
   "outputs": [],
   "source": [
    "# calculate model training accuracy\n",
    "from sklearn import metrics\n",
    "print('Training Accuracy:   {:01.3f}'.format(metrics.accuracy_score(y_train, y_train_predict)))\n",
    "\n",
    "# calculate model validation accuracy\n",
    "print('Validation Accuracy: {:01.3f}'.format(metrics.accuracy_score(y_val, y_val_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_NEuINphjha5"
   },
   "source": [
    "Notice that our **training accuracy** is higher than our **validation accuracy**.  This is fairly typical, as  machine learning algorithms have a tendency to overfit the training data.  When choosing a model, it's a good idea to tune it such that you are not overfitting too much.\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/fittings.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLEkVGUX1XJY"
   },
   "source": [
    "Okay, so our decision tree got ~78% validation accuracy.  But how do we know if that's a \"good\" accuracy?  Let's look at the simple case where we have a model that always predicts the most common class.  How well would that do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1531079096861,
     "user": {
      "displayName": "Danelle Shah",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100860318553187717982"
     },
     "user_tz": 240
    },
    "id": "I3dLk7Gozt6j",
    "outputId": "320aa500-0602-41ec-e3ae-9a446586c639"
   },
   "outputs": [],
   "source": [
    "# examine the class distribution of the validation set (using a Pandas Series method)\n",
    "y_val.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ollw--0a0FuN"
   },
   "source": [
    "This means that a trivial model that always predicts 0 would be right ~62% of the time.  So our decision tree seems to be doing something.\n",
    "\n",
    "Now let's investigate the errors our model is making by looking at the confusion matrix:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/confusion matrix 2.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1531079099422,
     "user": {
      "displayName": "Danelle Shah",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100860318553187717982"
     },
     "user_tz": 240
    },
    "id": "Qw3xcAK3z5t-",
    "outputId": "887952b0-af67-45e9-e03b-bc98f5d90df0"
   },
   "outputs": [],
   "source": [
    "# Use sklearn to make the confusion matrix\n",
    "print('Confusion Matrix:')\n",
    "labels = [0,1]\n",
    "cm = metrics.confusion_matrix(y_val, y_val_predict, labels)\n",
    "print(cm)\n",
    "\n",
    "# Normalized confusion matrix\n",
    "print('\\nNormalized Confusion Matrix:')\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1531079101980,
     "user": {
      "displayName": "Danelle Shah",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100860318553187717982"
     },
     "user_tz": 240
    },
    "id": "eVNTxWYB1obX",
    "outputId": "1f820706-4f19-4d4d-e34a-f5387f435ee1"
   },
   "outputs": [],
   "source": [
    "# Or you can use pandas -- it's a little nicer to look at\n",
    "pd.crosstab(y_val, y_val_predict, rownames=['True'], colnames=['Predicted'], margins=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 841
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 575,
     "status": "ok",
     "timestamp": 1531079102888,
     "user": {
      "displayName": "Danelle Shah",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100860318553187717982"
     },
     "user_tz": 240
    },
    "id": "UXUOndg_1lGf",
    "outputId": "9c187437-ccf0-4bb9-fb7c-a766169613af"
   },
   "outputs": [],
   "source": [
    "# Visualize the confusion matrix\n",
    "def plot_cmatrix(cm,labels,title='Confusion Matrix'):\n",
    "  fig = plt.figure()\n",
    "  ax = fig.add_subplot(111)\n",
    "  cax = ax.matshow(cm,cmap='Reds')\n",
    "  plt.title('\\n'+title+'\\n', fontsize=20)\n",
    "  fig.colorbar(cax)\n",
    "  ax.set_xticklabels([''] + labels, fontsize=16)\n",
    "  ax.set_yticklabels([''] + labels, fontsize=16)\n",
    "  plt.xlabel('Predicted', fontsize=16)\n",
    "  plt.ylabel('True', fontsize=16)\n",
    "  plt.show()\n",
    "  \n",
    "plot_cmatrix(cm,labels)\n",
    "plot_cmatrix(cm_norm,labels,title='Normalized Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hczAcaUe4YP6"
   },
   "source": [
    "You can even make a confusion matrix for the multi-class problem!  Check out this toy example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 449,
     "status": "ok",
     "timestamp": 1531079117276,
     "user": {
      "displayName": "Danelle Shah",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100860318553187717982"
     },
     "user_tz": 240
    },
    "id": "w2f3hsH04YiW",
    "outputId": "0216a517-eed9-4d35-e29b-d5e4b5a2969d"
   },
   "outputs": [],
   "source": [
    "y2=pd.Series(['dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'dog', 'frog', 'dog', 'dog', 'cat', 'frog'])\n",
    "y2pred=pd.Series(['dog', 'cat', 'dog', 'dog', 'cat', 'frog', 'cat', 'cat', 'dog', 'cat', 'dog', 'frog', 'frog', 'dog', 'cat', 'frog'])\n",
    "\n",
    "animal_labels=['cat','dog','frog']\n",
    "cm = metrics.confusion_matrix(y2,y2pred, animal_labels)\n",
    "plot_cmatrix(cm,animal_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Fkg_EdKahkl"
   },
   "source": [
    "### More Metrics\n",
    "There are several useful metrics that are derived from the confusion matrix:\n",
    "* sensitivity, **recall**, hit rate, or true positive rate (TPR) : $ \\mathrm {TPR} ={\\frac {\\mathrm {TP} }{P}}={\\frac {\\mathrm {TP} }{\\mathrm {TP} +\\mathrm {FN} }}$\n",
    " \n",
    "* **precision** or positive predictive value (PPV) : $ \\mathrm {PPV} ={\\frac {\\mathrm {TP} }{\\mathrm {TP} +\\mathrm {FP} }}$\n",
    "\n",
    "* specificity or true negative rate (TNR) : $\\mathrm {TNR} ={\\frac {\\mathrm {TN} }{N}}={\\frac {\\mathrm {TN} }{\\mathrm {TN} +\\mathrm {FP} }}$\n",
    "\n",
    "* miss rate or false negative rate (FNR) : $ \\mathrm {FNR} ={\\frac {\\mathrm {FN} }{P}}={\\frac {\\mathrm {FN} }{\\mathrm {FN} +\\mathrm {TP} }}=1-\\mathrm {TPR}$\n",
    "\n",
    "* fall-out or false positive rate (FPR) : $\\mathrm {FPR} ={\\frac {\\mathrm {FP} }{N}}={\\frac {\\mathrm {FP} }{\\mathrm {FP} +\\mathrm {TN} }}=1-\\mathrm {TNR} $\n",
    "\n",
    "* accuracy (ACC) : $\\mathrm {ACC} ={\\frac {\\mathrm {TP} +\\mathrm {TN} }{P+N}}={\\frac {\\mathrm {TP} +\\mathrm {TN} }{\\mathrm {TP} +\\mathrm {TN} +\\mathrm {FP} +\\mathrm {FN} }}$\n",
    "\n",
    "The F1 score is the harmonic mean of precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. The formula for the F1 score is:\n",
    " * F1 score: $F_{1}=2\\cdot {\\frac {\\mathrm {PPV} \\cdot \\mathrm {TPR} }{\\mathrm {PPV} +\\mathrm {TPR} }}={\\frac {2\\mathrm {TP} }{2\\mathrm {TP} +\\mathrm {FP} +\\mathrm {FN} }}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 185,
     "status": "ok",
     "timestamp": 1531080153756,
     "user": {
      "displayName": "Danelle Shah",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100860318553187717982"
     },
     "user_tz": 240
    },
    "id": "iLRgnLA11eT-",
    "outputId": "d56f126d-32a5-4d67-8948-2744e07e87cf"
   },
   "outputs": [],
   "source": [
    "print('Precision: {:01.3f}'.format(metrics.precision_score(y_val,y_val_predict)))\n",
    "print('Recall:    {:01.3f}'.format(metrics.accuracy_score(y_val,y_val_predict)))\n",
    "print('F1 score:  {:01.3f}'.format(metrics.f1_score(y_val,y_val_predict)))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fY2Bf6446CT8"
   },
   "source": [
    "## Evaluate the model on the validation data set (part 2)\n",
    "\n",
    "Up to now, we've simply been evaluating our model's ability to predict the correct class.  But in many (most) cases, our model actually outputs a *probability* or *certainty* over the class labels.  Let's take a look at the output of our decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1531080212244,
     "user": {
      "displayName": "Danelle Shah",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100860318553187717982"
     },
     "user_tz": 240
    },
    "id": "nzlcegvR1a35",
    "outputId": "18878827-d104-4c81-a00c-462e3c9c70c2"
   },
   "outputs": [],
   "source": [
    "# Predict class label probabilities\n",
    "labels = [0,1]\n",
    "y_val_prob = model.predict_proba(X_val,labels)\n",
    "\n",
    "# Output predicted and true values for the first validation point\n",
    "print('Probabilities:\\n',y_val_prob[0])\n",
    "print('\\nTrue Value:\\n',y_val.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-0_TqOn0Bh53"
   },
   "source": [
    "Notice that the decision tree predicts that there is a ~87% probability that this data point belongs to class label 1.  But this doesn't necessarily mean we *have* to label the data point as class 1.  For example, we may decide to say that we need to be 90% confident that the data belongs to class 1, otherwise we say it belongs to class 0.  The predicted class will depend on where we threshold our decision boundary.  \n",
    "\n",
    "\n",
    "Choosing a threshold is not always as straighforward as choosing the label with the greatest probability.  Particularly in cases where your data set is very biased or there is a greater penalty for false positives than false negatives (and vice-versa), it is often desirable to evaluate the model over all thresholds.  This is where the **Receiver Operating Characteristic (ROC) curve** comes in!\n",
    "\n",
    "\n",
    "The ROC curve is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied.  The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.\n",
    "\n",
    "\n",
    "The **area under the curve (AUC) ** is often used as a more robust and descriptive metric of a classification model's performance, where an AUC of 1 is \"perfect\" and an AUC of 0 means that the classifier is no better than random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1oLYVkqEyWIr"
   },
   "outputs": [],
   "source": [
    "# Calculate the FPR and TPR at varying thresholds (assume label 1 is the \"postive\" class)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_val, y_val_prob[:,1])\n",
    "\n",
    "# Calculate the area under the ROC curve\n",
    "roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1531081849861,
     "user": {
      "displayName": "Danelle Shah",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100860318553187717982"
     },
     "user_tz": 240
    },
    "id": "anbcgur8ypbj",
    "outputId": "e99e2c53-1a39-4d5e-d02c-e671d76bc04b"
   },
   "outputs": [],
   "source": [
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(6,6))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gk4nnCIYgXMX"
   },
   "source": [
    "## Some additional exercises to do on your own:\n",
    "* Perform the same analysis above using [k-fold cross validation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n",
    "* Choose a \"good\" threshold for your decision tree (according to some metric, e.g., minimizing False Positives)\n",
    "* Evaluate the TEST data using the model at your chosen threshold -- how does your classifier perform?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "model_evaluation.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
